# Installing Hadoop 2.8.1 on Mac OS X 10.12.6 via Homebrew
## Prerequisites
- Java
```
$ java -version
java version "1.8.0_144"
Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
```
- Ruby & Homebrew
```
$ ruby -e "$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)"
```
- SSH
Check for the existance of `~/.ssh/id_rsa` and `~/.ssh/id_rsa.pub` files.
If not, the keys can be generated by
```
ssh-keygen -t rsa
```
 - Enable Remote Login
"System Preferences" -> "Sharing" -> Check "Remote Login"
 - Authorize SSH keys
```
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```

## Install Hadoop
```
$ brew install Hadoop
```

## Configure Hadoop
- Create HDFS directory:
```
mkdir -p ~/hadoop/data/namenode
mkdir -p ~/hadoop/data/datanode
```
- Go to Hadoop directory:
```
$ cd /usr/local/Cellar/hadoop/2.8.1/libexec/etc/hadoop
```
- Edit *hadoop-env.sh*
Replace
```
export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"
```
by
```
export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc="
```
- Edit *Core-site.xml*
```
<configuration>  
<property>
     <name>hadoop.tmp.dir</name>
     <value>/usr/local/Cellar/hadoop/hdfs/tmp</value>
     <description>A base for other temporary directories.</description>
  </property>
  <property>
     <name>fs.default.name</name>                                     
     <value>hdfs://localhost:9000</value>                             
  </property>
</configuration>
```

Edit *hdfs-site.xml*
```
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>${user.home}/hadoop/data/namenode</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>${user.home}/hadoop/data/datanode</value>
  </property
</configuration>
```

- Edit *mapred-site.xml*
```
<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>localhost:9010</value>
  </property>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
</configuration>
```
- Edit *yarn-site.xml*
<configuration>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>localhost:8032</value>
    </property>
    <property>
      <name>yarn.nodemanager.aux-services</name>
      <value>mapreduce_shuffle</value>
    </property>
</configuration>

## Format HDFS
```
$ hdfs namenode -format
```

## Start Hadoop
```
$ cd /usr/local/Cellar/hadoop/2.8.1/libexec/sbin
$ ./start-dfs.sh
$ ./start-yarn.sh
```
or
edit ~/.profile or ~/.bashrc
```
alias hstart="/usr/local/Cellar/hadoop/2.6.0/sbin/start-dfs.sh;/usr/local/Cellar/hadoop/2.6.0/sbin/start-yarn.sh"
alias hstop="/usr/local/Cellar/hadoop/2.6.0/sbin/stop-yarn.sh;/usr/local/Cellar/hadoop/2.6.0/sbin/stop-dfs.sh"
```
then
```
$source ~/.profile
```
Now we can run Hadoop by
```
$ hstart
```
If you get the warning:
> WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
It is because you are running on 64-bit but Hadoop native library is 32-bit. This is not a big issue.

## Testing
- Access Hadoop web interfaces
> JobTracker: http://localhost:8088
> Resource Manager: http://localhost:50070
> Specific Node Information: http://localhost:8042

- Check status
```
$ jps
13712 NameNode
12678 DataNode
12920 ResourceManager
12793 SecondaryNameNode
14042 Jps
13023 NodeManager
```
- MapReduce jobs
```
$ hadoop jar /usr/local/Cellar/hadoop/2.8.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar pi 2 5
Number of Maps = 2
Samples per Map = 5
...
Job Finished in 25.288 seconds
Estimated value of Pi is 3.6000000000000000
```

## Stop Hadoop
```
$ hstop
```
