# Get Started with Spark SQL
Spark SQL provides a special type of RDD called **SchemaRDD**, which is an RDD of Row objects.

## Connecting Spark SQL to Apache Hive  
You need to provide a Hive configuration. You do so by coping your hive-site.xml file within your Hive installation to Spark's *./conf/* directory. If done, you can create a HiveContext object and write HiveQL queries to get your data.
- Creating a HiveContext and selecting data in Python
```python
from pyspark.sql import HiveContext

hc = HiveContext(sc)
rows = hc.sql("SELECT name, age FROM users")
firstRow = rows.first()
print firstRow.name
```
- Loading JSON data and selecting data in Pyhton
```python
tweets = hc.jsonFile("tweets.json")
tweets.registerTempTable("tweets")
results = hc.sql("SELECT user.name, text FROM tweets")
```






