# Installing Hadoop on Mac OS X via Homebrew
## Prerequisites
- Java
```
$ java -version
java version "1.8.0_144"
Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
```
- Ruby & Homebrew
```
$ ruby -e "$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)"
```
- SSH
Check for the existance of `~/.ssh/id_rsa` and `~/.ssh/id_rsa.pub` files.
If not, the keys can be generated by
```
ssh-keygen -t rsa
```
 - Enable Remote Login
"System Preferences" -> "Sharing" -> Check "Remote Login"
 - Authorize SSH keys
```
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```

## Install Hadoop
```
$ brew install Hadoop
```

## Configure Hadoop
Hadoop can be run in one of the three modes: Standalone(local) mode, Pseudodistributed mode, Fully distributed mode. The configuration files for the Pseudodistributed mode is provided here.
- Go to Hadoop directory:
```
$ cd /usr/local/Cellar/hadoop/2.8.1/libexec/etc/hadoop
```
- Edit *hadoop-env.sh*

Replace
```
export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"
```
with
```
export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc="
```

- Edit *Core-site.xml*
```
<configuration>  
<property>
     <name>hadoop.tmp.dir</name>
     <value>/usr/local/Cellar/hadoop/hdfs/tmp</value>
     <description>A base for other temporary directories.</description>
  </property>
  <property>
     <name>fs.defaultFS</name>                                     
     <value>hdfs://localhost/</value>                             
  </property>
</configuration>
```

- Edit *hdfs-site.xml*
```
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
</configuration>
```

- Edit *mapred-site.xml*
```
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
</configuration>
```
- Edit *yarn-site.xml*
```
<configuration>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>localhost</value>
    </property>
    <property>
      <name>yarn.nodemanager.aux-services</name>
      <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

## Start Hadoop
- Format HDFS
```
$ hdfs namenode -format
```

- Run Hadoop
```
$ cd /usr/local/Cellar/hadoop/2.8.1/libexec/sbin
$ ./start-dfs.sh
$ ./start-yarn.sh
```
or
```
$ ./start-all.sh
```
or edit ~/.profile or ~/.bashrc
```
alias hstart="/usr/local/Cellar/hadoop/2.8.1/sbin/start-dfs.sh;/usr/local/Cellar/hadoop/2.8.1/sbin/start-yarn.sh"
alias hstop="/usr/local/Cellar/hadoop/2.8.1/sbin/stop-yarn.sh;/usr/local/Cellar/hadoop/2.8.1/sbin/stop-dfs.sh"
```
and then
```
$source ~/.profile
```
Now we can run Hadoop using
```
$ hstart
```
If you get the warning:
> WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

It is because you are running on 64-bit but Hadoop native library is 32-bit.

## Testing
- Access Hadoop web UI
> - Resource Manager page: http://localhost:8088
> - HDFS status: http://localhost:50070
> - Secondary NameNode status: http://localhost:50090

- Check status
```
$ jps
13712 NameNode
12678 DataNode
12920 ResourceManager
12793 SecondaryNameNode
14042 Jps
13023 NodeManager
```
- Run a MapReduce job
```
$ hadoop jar /usr/local/Cellar/hadoop/2.8.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar pi 2 5
Number of Maps = 2
Samples per Map = 5
...
Job Finished in 25.288 seconds
Estimated value of Pi is 3.6000000000000000
```

## Stop Hadoop
```
$ hstop
```
