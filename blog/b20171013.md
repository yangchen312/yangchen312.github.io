# Hadoop Related Projects
## Avro
  A language-independent data serialization system
  * Install Avro for Python
    ```
    $ easy_install avro
    ```

  * Avro tools for Java

    You can download Avro tools written in Java directly from the website:
    http://www.apache.org/dyn/closer.cgi/avro/.

## Parquet
  A columnar storage format that can efficiently store nested data
  * Download Parquet tools

    You can download Parquet tools from the Parquet Maven repository. Search for "parquet-tools" on http://seach.maven.org
    * Get the metadata of a Parquet file
    ```
    $ java -jar parquet-tools-*.jar meta data.parquet
    ```
## Flume
  It's designed for high-volume ingestion into Hadoop of even-based (streaming) data.
  * Flume agent

    To use Flume, you need to run a Flume agent, which is a long-lived Java that runs sources and sinks (data destination, e.g. HDFS), connected by channels. A basic Flume building block is a **source-channel-sink** combination.

  * Installing Flume
    1. Download Flume binary release from the website: https://flume.apache.org/download.html.
    2. Move/copy and unpack the archive file in a suitable location, here it is `/usr/local`.
    ```
    $ sudo cp apache-flume-1.8.0-bin.tar.gz /usr/local/
    $ cd /usr/local
    $ sudo tar -xzvf apache-flume-1.8.0-bin.tar.gz
    $ sudo mv apache-flume-1.8.0-bin flume
    ```
    3. Put the Flume binary on your path by adding below lines into `~/.profile` or `/.bashrc`.
    ```
    $ sudo nano ~/.bashrc
    ```
    Append below lines in `~/.bashrc`:
    ```
    export FLUME_HOME=/usr/local/flume
    export FLUME_CONF_DIR=$FLUME_HOME/conf
    export FLUME_CLASSPATH=$FLUME_CONF_DIR
    export PATH=$PATH:$FLUME_HOME/bin
    ```
    4. Instantiate `flume-env.sh` and `flume-conf.properties`
    ```
    $ sudo cp conf/flume-env.sh.template conf/flume-env.sh
    $ sudo cp conf/flume-conf.properties.template conf/flume-conf.properties
    ```
    Add the following lines in `flume-env.sh`.
    ```
    export JAVA_HOME="$(/usr/libexec/java_home)"
    ```

  * An example
    - Firstly, specify the cofiguration file. Here is an example.
    ```
    # conf/flume-conf.properties

    # Name components
    agent1.sources = source1
    agent1.channels = channel1
    agent1.sinks = sink1

    # Bind source and sink to channel
    agent1.sources.source1.channels = channel1
    agent1.sinks.sink1.channel = channel1

    # Describe source
    agent1.sources.source1.type = spooldir
    agent1.sources.source1.spoolDir = /tmp/spooldir

    # Describe sink
    agent1.sinks.sink1.type = logger

    # Describe channel
    agent1.channels.channel1.type = file
    ```
    - Create the spooling directory
    ```
    $ sudo mkdir /tmp/spooldir
    $ sudo chown -R user_name:group_name /tmp/spooldir/
    ```
    - Start the Flume agent
    ```
    $ sudo flume-ng agent --conf-file conf/flume-conf.properties --name agent1 --conf $FLUME_HOME/conf -Dflume.root.logger=INFO,console
    ```
    - In a new terminal, create a file in the spooling directory.
    ```
    $ sudo echo "Hello Flume" > /tmp/spooldir/.file1.txt
    $ mv /tmp/spooldir/.file1.txt /tmp/spooldir/file1.txt
    ```
    - In the agent's terminal, you will see that Flume has detected and processed the file.
    ```
    Preparing to move file /tmp/spooldir/file1.txt to /tmp/spooldir/file1.txt.COMPLETED
    Event: { headers:{} body: 48 65 6C 6C 6F 20 46 6C 75 6D 65                Hello Flume }
    ```
      The file was renamed to `file1.txt.COMPLETED` by the source, which indicates that Flume won't process it again.
